{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SiTIlmI3yor_xhnI-aeDpvCL3t2wv-7n",
      "authorship_tag": "ABX9TyO2Dik5gCl8wOACdMHNW4Hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AROM98/spln3/blob/main/fasttext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwoc0aHBosm7",
        "outputId": "f7c808cc-45e4-40a9-a8b4-0722a75241d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3141052 sha256=3a5c65948d78c381fd61925104608270e5624b0ec5f4c402dbaa77e660b7a4db\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wtTASHq0laJ8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import fasttext\n",
        "\n",
        "## Na primeira vez, tenho que usar os vetores que fiz download\n",
        "## link de download: https://fasttext.cc/docs/en/pretrained-vectors.html\n",
        "\n",
        "#pt_dictionary = FastVector(vector_file='wiki.pt.vec')\n",
        "#en_dictionary = FastVector(vector_file='wiki.en.vec')\n",
        "\n",
        "## e Ajusta-los com estas tranformações, e sarlvar num ficheiro\n",
        "# pt_dictionary.apply_transform('alignment_matrices/pt.txt')\n",
        "# en_dictionary.apply_transform('alignment_matrices/en.txt')\n",
        "# print(\"Vou escrever os ficheiros:\")\n",
        "# pt_dictionary.export(\"pt_model.txt\")\n",
        "# print(\"Acabei 1\")\n",
        "# en_dictionary.export(\"en_model.txt\")\n",
        "# print(\"Acabei 2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Copyright (c) 2017-present, babylon health\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the BSD-style license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class FastVector:\n",
        "    \"\"\"\n",
        "    Minimal wrapper for fastvector embeddings.\n",
        "    ```\n",
        "    Usage:\n",
        "        $ model = FastVector(vector_file='/path/to/wiki.en.vec')\n",
        "        $ 'apple' in model\n",
        "        > TRUE\n",
        "        $ model['apple'].shape\n",
        "        > (300,)\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vector_file='', transform=None):\n",
        "        \"\"\"Read in word vectors in fasttext format\"\"\"\n",
        "        self.word2id = {}\n",
        "\n",
        "        # Captures word order, for export() and translate methods\n",
        "        self.id2word = []\n",
        "\n",
        "        print('reading word vectors from %s' % vector_file)\n",
        "        with open(vector_file, 'r') as f:\n",
        "            (self.n_words, self.n_dim) = \\\n",
        "                (int(x) for x in f.readline().rstrip('\\n').split(' '))\n",
        "            self.embed = np.zeros((self.n_words, self.n_dim))\n",
        "            for i, line in enumerate(f):\n",
        "                elems = line.rstrip('\\n').split(' ')\n",
        "                self.word2id[elems[0]] = i\n",
        "                self.embed[i] = elems[1:self.n_dim+1]\n",
        "                self.id2word.append(elems[0])\n",
        "        \n",
        "        # Used in translate_inverted_softmax()\n",
        "        self.softmax_denominators = None\n",
        "        \n",
        "        if transform is not None:\n",
        "            print('Applying transformation to embedding')\n",
        "            self.apply_transform(transform)\n",
        "\n",
        "    def apply_transform(self, transform):\n",
        "        \"\"\"\n",
        "        Apply the given transformation to the vector space\n",
        "\n",
        "        Right-multiplies given transform with embeddings E:\n",
        "            E = E * transform\n",
        "\n",
        "        Transform can either be a string with a filename to a\n",
        "        text file containing a ndarray (compat. with np.loadtxt)\n",
        "        or a numpy ndarray.\n",
        "        \"\"\"\n",
        "        transmat = np.loadtxt(transform) if isinstance(transform, str) else transform\n",
        "        self.embed = np.matmul(self.embed, transmat)\n",
        "\n",
        "    def export(self, outpath):\n",
        "        \"\"\"\n",
        "        Transforming a large matrix of WordVectors is expensive. \n",
        "        This method lets you write the transformed matrix back to a file for future use\n",
        "        :param The path to the output file to be written \n",
        "        \"\"\"\n",
        "        fout = open(outpath, \"w\")\n",
        "\n",
        "        # Header takes the guesswork out of loading by recording how many lines, vector dims\n",
        "        fout.write(str(self.n_words) + \" \" + str(self.n_dim) + \"\\n\")\n",
        "        for token in self.id2word:\n",
        "            vector_components = [\"%.6f\" % number for number in self[token]]\n",
        "            vector_as_string = \" \".join(vector_components)\n",
        "\n",
        "            out_line = token + \" \" + vector_as_string + \"\\n\"\n",
        "            fout.write(out_line)\n",
        "\n",
        "        fout.close()\n",
        "\n",
        "    def translate_nearest_neighbour(self, source_vector):\n",
        "        \"\"\"Obtain translation of source_vector using nearest neighbour retrieval\"\"\"\n",
        "        similarity_vector = np.matmul(FastVector.normalised(self.embed), source_vector)\n",
        "        target_id = np.argmax(similarity_vector)\n",
        "        return self.id2word[target_id]\n",
        "\n",
        "    def translate_inverted_softmax(self, source_vector, source_space, nsamples,\n",
        "                                   beta=10., batch_size=100, recalculate=True):\n",
        "        \"\"\"\n",
        "        Obtain translation of source_vector using sampled inverted softmax retrieval\n",
        "        with inverse temperature beta.\n",
        "\n",
        "        nsamples vectors are drawn from source_space in batches of batch_size\n",
        "        to calculate the inverted softmax denominators.\n",
        "        Denominators from previous call are reused if recalculate=False. This saves\n",
        "        time if multiple words are translated from the same source language.\n",
        "        \"\"\"\n",
        "        embed_normalised = FastVector.normalised(self.embed)\n",
        "        # calculate contributions to softmax denominators in batches\n",
        "        # to save memory\n",
        "        if self.softmax_denominators is None or recalculate is True:\n",
        "            self.softmax_denominators = np.zeros(self.embed.shape[0])\n",
        "            while nsamples > 0:\n",
        "                # get batch of randomly sampled vectors from source space\n",
        "                sample_vectors = source_space.get_samples(min(nsamples, batch_size))\n",
        "                # calculate cosine similarities between sampled vectors and\n",
        "                # all vectors in the target space\n",
        "                sample_similarities = \\\n",
        "                    np.matmul(embed_normalised,\n",
        "                              FastVector.normalised(sample_vectors).transpose())\n",
        "                # accumulate contribution to denominators\n",
        "                self.softmax_denominators \\\n",
        "                    += np.sum(np.exp(beta * sample_similarities), axis=1)\n",
        "                nsamples -= batch_size\n",
        "        # cosine similarities between source_vector and all target vectors\n",
        "        similarity_vector = np.matmul(embed_normalised,\n",
        "                                      source_vector/np.linalg.norm(source_vector))\n",
        "        # exponentiate and normalise with denominators to obtain inverted softmax\n",
        "        softmax_scores = np.exp(beta * similarity_vector) / \\\n",
        "                         self.softmax_denominators\n",
        "        # pick highest score as translation\n",
        "        target_id = np.argmax(softmax_scores)\n",
        "        return self.id2word[target_id]\n",
        "\n",
        "    def get_samples(self, nsamples):\n",
        "        \"\"\"Return a matrix of nsamples randomly sampled vectors from embed\"\"\"\n",
        "        sample_ids = np.random.choice(self.embed.shape[0], nsamples, replace=False)\n",
        "        return self.embed[sample_ids]\n",
        "\n",
        "    @classmethod\n",
        "    def normalised(cls, mat, axis=-1, order=2):\n",
        "        \"\"\"Utility function to normalise the rows of a numpy array.\"\"\"\n",
        "        norm = np.linalg.norm(\n",
        "            mat, axis=axis, ord=order, keepdims=True)\n",
        "        norm[norm == 0] = 1\n",
        "        return mat / norm\n",
        "    \n",
        "    @classmethod\n",
        "    def cosine_similarity(cls, vec_a, vec_b):\n",
        "        \"\"\"Compute cosine similarity between vec_a and vec_b\"\"\"\n",
        "        return np.dot(vec_a, vec_b) / \\\n",
        "            (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n",
        "\n",
        "    def __contains__(self, key):\n",
        "        return key in self.word2id\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.embed[self.word2id[key]]\n"
      ],
      "metadata": {
        "id": "Q3thj3ndrL0e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_dictionary = FastVector(vector_file='/content/drive/MyDrive/SPLN/pt_model.txt')\n",
        "en_dictionary = FastVector(vector_file='/content/drive/MyDrive/SPLN/en_model.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxy2snV0l8zP",
        "outputId": "288c1cc5-7240-4cb3-c24b-07b99485b796"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading word vectors from /content/drive/MyDrive/SPLN/pt_model.txt\n",
            "reading word vectors from /content/drive/MyDrive/SPLN/en_model.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## codigo para frases, palavra a palavra (EN -> PT)\n",
        "aux = \"always sat with his back to the window in his office on the ninth floor\"\n",
        "aux = re.split(r\" \", aux)\n",
        "res = \"\"\n",
        "for word in aux:\n",
        "    en_vector = en_dictionary[word]\n",
        "    res += \" \" + pt_dictionary.translate_nearest_neighbour(en_vector)\n",
        "\n",
        "print(\"Tradução: \", res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1SvJEgHlmNm",
        "outputId": "18874572-001d-4f01-89b4-fb17081f7469"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tradução:   sempre cnvp com seu voltar para a janela em seu escritório em a oitavo térreo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## traduz palavra dada como input (EN -> PT)\n",
        "while True:\n",
        "    print(\"introduza palavra a traduzir para português: \")\n",
        "    valor = input()\n",
        "    print(\"---> \", valor)\n",
        "    en_vector = en_dictionary[valor]\n",
        "    print(\"Tradução: \",pt_dictionary.translate_nearest_neighbour(en_vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qJG6PBnil0zV",
        "outputId": "a3a2c44b-63f1-4b3b-995f-66290e049678"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "introduza palavra a traduzir para português: \n",
            "hello\n",
            "--->  hello\n",
            "Tradução:  olá\n",
            "introduza palavra a traduzir para português: \n",
            "bye\n",
            "--->  bye\n",
            "Tradução:  repescagem\n",
            "introduza palavra a traduzir para português: \n",
            "dog\n",
            "--->  dog\n",
            "Tradução:  cachorro\n",
            "introduza palavra a traduzir para português: \n",
            "cat\n",
            "--->  cat\n",
            "Tradução:  gato\n",
            "introduza palavra a traduzir para português: \n",
            "bird\n",
            "--->  bird\n",
            "Tradução:  pássaros\n",
            "introduza palavra a traduzir para português: \n",
            "cloud\n",
            "--->  cloud\n",
            "Tradução:  nuvem\n",
            "introduza palavra a traduzir para português: \n",
            "building\n",
            "--->  building\n",
            "Tradução:  edifício\n",
            "introduza palavra a traduzir para português: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \"\"\"\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6a95a142ef57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"introduza palavra a traduzir para português: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---> \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0men_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}